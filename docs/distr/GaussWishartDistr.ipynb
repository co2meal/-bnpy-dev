{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Gauss-Wishart\n",
      "\n",
      "## Goal\n",
      "\n",
      "Describes a **bnpy** Distr object: the Gaussian-Wishart distribution with $D$ dimensions. \n",
      "\n",
      "The Gaussian-Wishart is a multivariate generalization of the Gaussian-Gamma distribution, and a useful joint prior for learning means and covariance matrices.\n",
      "\n",
      "## Basic Notation\n",
      "\n",
      "We have a joint distribution\n",
      "$$\n",
      "\\mu, \\Lambda \\sim \\mbox{Gauss-Wishart}( \\mu, \\Lambda \\mid v, W, m, \\kappa)\n",
      "$$\n",
      "\n",
      "which factorizes as follows\n",
      "$$\n",
      "\\Lambda \\sim \\mbox{Wishart}(\\Lambda \\mid v, W)\n",
      "\\\\\n",
      "\\mu \\mid \\Lambda \\sim \\mbox{Normal}(\\mu \\mid m, (\\kappa \\Lambda)^{-1} ) \n",
      "$$\n",
      "\n",
      "### Parameters\n",
      "\n",
      "Square matrix $\\Lambda$ represents a precision matrix. It has size $D \\times D$, and is both symmetric and positive definite.\n",
      "\n",
      "Vector $\\mu$ represents a location. It has length $D$.\n",
      "\n",
      "### Hyperparameters\n",
      "\n",
      "The Wishart distribution over $\\Lambda$ is specified by a scalar $v$ and a square matrix $W$, of size $D \\times D$.\n",
      "\n",
      "* Scalar $v$ is always positive, and represents the degrees-of-freedom.\n",
      "* Matrix $W$ is always symmetric and positive definite.\n",
      "\n",
      "The Normal distribution over $\\mu$ is specified by vector $m$ and precision matrix $\\kappa \\Lambda$.\n",
      "\n",
      "* Scalar $\\kappa$ is always positive.\n",
      "* Vector $m$ has length $D$ and takes real-valued entries.\n",
      "\n",
      "### Generating Data\n",
      "\n",
      "Each observated data point $x_n$ is a $D$-dimensional vector. \n",
      "\n",
      "We sample $x_n$ from a normal distribution with mean $\\mu$ and precision matrix $\\Lambda$.\n",
      "\n",
      "$$\n",
      "x \\sim \\mbox{Normal}( x \\mid \\mu, \\Lambda^{-1} )\n",
      "$$\n",
      "\n",
      "equivalently, if we define $\\Sigma = \\Lambda^{-1}$, then\n",
      "\n",
      "$$\n",
      "x \\sim \\mbox{Normal}( x \\mid \\mu, \\Sigma )\n",
      "$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Useful moments\n",
      "\n",
      "#### Expected value of matrix $\\Lambda$\n",
      "\\begin{align}\n",
      "\\mbox{E}[ \\Lambda ] = v W\n",
      "\\end{align}\n",
      "\n",
      "#### Expected value of vector $\\mu$\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\mu] = m\n",
      "\\end{align}\n",
      "\n",
      "#### Covariance of vector $\\mu$\n",
      "\\begin{align}\n",
      "\\mbox{Cov}[\\mu] \n",
      "&= ( \\kappa \\Lambda )^{-1}\n",
      "%&= \\mbox{E}[(\\mu - m)(\\mu - m)^T]\n",
      "%&= \\mbox{E}[\\mu \\mu^T] - \\mbox{E}[\\mu] m - m \\mbox{E}[\\mu] + m m^T\n",
      "\\end{align}\n",
      "\n",
      "#### Expected value of $\\mu \\mu^T$\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\mu \\mu^T ] \n",
      "&= \\mbox{Cov}[\\mu] + \\mbox{E}[\\mu]\\mbox{E}[\\mu]^T\n",
      "\\\\\n",
      "&= (\\kappa \\Lambda)^{-1} + m m^T\n",
      "\\end{align}\n",
      "\n",
      "#### Expected value of $\\Lambda \\mu$\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\Lambda \\mu] \n",
      "&= \\int_{\\Lambda} p(\\Lambda)  \\int_{\\mu} p(\\mu | \\Lambda) \\Lambda \\mu ~d\\mu ~d\\Lambda\n",
      "\\\\\n",
      "&= \\int_{\\Lambda} p(\\Lambda) \\Lambda  ~ d\\Lambda ~ [ m ]\n",
      "\\\\\n",
      "&= v W m = \\mbox{E}[\\Lambda] \\mbox{E}[ \\mu ]\n",
      "\\end{align}\n",
      "\n",
      "\n",
      "#### Expected value of $\\Lambda \\mu \\mu^T$\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\Lambda \\mu] \n",
      "&= \\int_{\\Lambda} p(\\Lambda)  \\int_{\\mu} p(\\mu | \\Lambda) \\Lambda \\mu \\mu^T ~d\\mu ~d\\Lambda\n",
      "\\\\\n",
      "&= \\int_{\\Lambda} p(\\Lambda) \\Lambda \\Big(\\kappa^{-1} \\Lambda^{-1} + m m^T \\Big) ~ d\\Lambda\n",
      "\\\\\n",
      "&= \\kappa^{-1} + v W m m^T\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Expected mahalonobis distance\n",
      "\n",
      "For a $D$-length vector $x$, we have\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[ (x - \\mu)^T \\Lambda (x - \\mu) ] \n",
      "&= \\mbox{E}[ \\mbox{tr}(\\Lambda (x-\\mu) (x-\\mu)^T) ]\n",
      "\\\\\n",
      "&= \\mbox{E}[ \\mbox{tr}\\Big(\\Lambda ( xx^T - x \\mu - \\mu x + \\mu \\mu^T ) \\Big) ]\n",
      "\\\\\n",
      "&= \\mbox{E}[ \\mbox{tr}\\Big(\\Lambda  xx^T \\Big)\n",
      "             - \\mbox{tr}\\Big(\\Lambda (x \\mu + \\mu x ) \\Big)\n",
      "             + \\mbox{tr}\\Big( \\Lambda \\mu \\mu^T \\Big) ]\n",
      "\\\\\n",
      "&=  \\mbox{tr}\\Big(\\mbox{E}[\\Lambda]  xx^T \\Big)\n",
      "             - \\mbox{tr}\\Big( \\mbox{E}[\\mu^T \\Lambda] x )\n",
      "             - \\mbox{tr}\\Big( \\mbox{E}[\\Lambda \\mu] x^T )\n",
      "             + \\mbox{tr}\\Big( \\mbox{E}[\\Lambda \\mu \\mu^T] \\Big)\n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( v W xx^T \\Big) - \\mbox{tr}(v m^T W x) - \\mbox{tr}(v W m x^T) + \\mbox{tr}\\Big(vW m m^T + \\kappa^{-1} \\Big)\n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( v W xx^T  - v m^T W x  - v x^T W m + v m^T W m  \\Big) + D \\kappa^{-1}\n",
      "\\\\\n",
      "&= v  \\Big( (x - m)^T W (x-m) \\Big) + D \\kappa^{-1}\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Expected value of log determinant: $\\log |\\Lambda |$\n",
      "According to Bishop B.81\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[ \\log |\\Lambda_d| ] \n",
      "&= D \\log 2 + \\log |W| + \\psi_D(\\frac{v}{2})\n",
      "\\end{align}\n",
      "\n",
      "where we've defined the multivariate digamma function\n",
      "\\begin{align}\n",
      "\\psi_D(a) = \\sum_{d=1}^D \\psi(a + \\frac{ 1 - d}{2}) \n",
      "\\end{align}\n",
      "\n",
      "#### Entropy of the Wishart\n",
      "\n",
      "According to Bishop B.83\n",
      "\\begin{align}\n",
      "\\mbox{H}[\\Lambda] = - \\log Z(v, W) - \\frac{v - D - 1}{2} \\mbox{E}[ \\log | \\Lambda |] + \\frac{vD}{2}\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LOG PDF : Separate Gaussian and Wishart terms\n",
      "\n",
      "### Log probability density function of the Gaussian over $\\mu$\n",
      "\n",
      "\\begin{align}\n",
      "\\log p(\\mu \\mid \\Lambda) &= -\\frac{D}{2} \\log [2\\pi] + \\frac{D}{2} \\log \\kappa + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m) \n",
      "\\end{align}\n",
      "\n",
      "\n",
      "### Log probability density function of Wishart over $\\Lambda$\n",
      "\n",
      "\\begin{align}\n",
      "\\log p(\\Lambda) &= - \\log Z(v,W) + \\frac{v - D - 1}{2} \\log |\\Lambda | - \\frac{1}{2} \\mbox{tr}(W^{-1} \\Lambda)\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Log normalization constant of Wishart Distribution\n",
      "\n",
      "\\begin{align}\n",
      "\\log Z(v, W) &= \\frac{vD}{2} \\log 2 + \\log \\Gamma_D(\\frac{v}{2}) - \\frac{v}{2} \\log |W^{-1}|\n",
      "\\\\\n",
      "&=  \\frac{vD}{2} \\log 2 + \\log \\Gamma_D(\\frac{v}{2}) + \\frac{v}{2} \\log |W|\n",
      "\\end{align}\n",
      "\n",
      "Remember there is always a reciprocal relationship between determinants of matrix inverses\n",
      "$$\n",
      "|W^{-1}| = \\frac{1}{|W|}\n",
      "$$\n",
      "so we can equivalently use either line above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LOG PDF: Joint Gaussian-Wishart\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( \\mu, \\Lambda) \n",
      "&= - \\log Z(v, W, m, \\kappa) \n",
      "   + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m) \n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\end{align}\n",
      "\n",
      "where\n",
      "\n",
      "\\begin{align}\n",
      "\\log Z(v, W, m, \\kappa) \n",
      "&= \\frac{D}{2} \\log [2\\pi] - \\frac{D}{2} \\log \\kappa + \\frac{vD}{2} \\log 2 + \\log \\Gamma_D(\\frac{v}{2}) + \\frac{v}{2} \\log |W|\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Expected log pdf \n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E} \\log p( \\mu, \\Lambda) \n",
      "&= - \\log Z(v, W, m, \\kappa) \n",
      "   + \\frac{1}{2} \\mbox{E}[\\log |\\Lambda|] - \\frac{\\kappa}{2} \\mbox{E}[(\\mu - m)^T \\Lambda (\\mu - m)] \n",
      "  + \\frac{v - D - 1}{2} \\mbox{E}[ \\log |\\Lambda|] - \\frac{1}{2} \\mbox{tr} \\Big( \\mbox{E}[\\Lambda] W^{-1} \\Big)\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LOG LIKELIHOOD \n",
      "\n",
      "Here we study the log pdf of the data-generating distribution.\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( x_n \\mid \\mu, \\Lambda)\n",
      "&= \\log \\mbox{Normal}( x_n \\mid \\mu, \\Lambda )\n",
      "\\\\\n",
      "&= - \\frac{D}{2} \\log [2\\pi] + \\frac{1}{2} \\log |\\Lambda| - \\frac{1}{2} (x_n - \\mu)^T \\Lambda^{-1} (x_n  - \\mu)\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Expected Log Likelihood\n",
      "\n",
      "Under a single distribution, we can find the expected log probability as follows, using the basic expectations defined above\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\log p(x_n | \\Lambda) ]\n",
      "&= - \\frac{D}{2} \\log [2\\pi] + \\frac{1}{2} \\mbox{E}[\\log |\\Lambda|] - \\frac{1}{2} \\mbox{E}\\Big[ (x_n - \\mu)^T \\Lambda (x_n - \\mu) \\Big]\n",
      "\\end{align}\n",
      "\n",
      "Where we make use of the expected mahalanobis distance defined above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Posterior updates\n",
      "\n",
      "After seeing $N$ data items, we have the following posterior distribution\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( \\mu, \\Lambda \\mid \\{x_n\\}_{n=1}^N, v, W, m, \\kappa) \n",
      "&= \\log p(\\mu, \\Lambda \\mid v, W, m, \\kappa) + \\sum_{n=1}^N \\log p( x_n \\mid \\mu, \\Lambda)\n",
      "\\end{align}\n",
      "\n",
      "If we expand the prior and likelihood terms (one on each line), we find\n",
      "\\begin{align}\n",
      "\\log p( \\mu, \\Lambda \\mid \\{x_n\\}_{n=1}^N, v, W, m, \\kappa) \n",
      "&= - \\log Z(v, W, m, \\kappa) + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)\n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\\\ &\\quad\n",
      "  + \\sum_{n=1}^N -\\frac{D}{2}\\log [2\\pi] + \\frac{1}{2} \\log |\\Lambda| - \\frac{1}{2} (x_n - \\mu)^T \\Lambda (x_n - \\mu)\n",
      "\\\\\n",
      "&= - \\log Z(v, W, m, \\kappa) + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)\n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\\\ &\\quad\n",
      "  -\\frac{ND}{2}\\log [2\\pi] + \\frac{N}{2} \\log |\\Lambda| - \\frac{1}{2} \\sum_{n=1}^N(x_n - \\mu)^T \\Lambda (x_n - \\mu)\n",
      "\\end{align}\n",
      "\n",
      "Now, if we rearrange terms so that the first line has $\\log |\\Lambda|$, second line has $\\Lambda$, and the final lines have quadratic forms $\\mu ^T \\Lambda \\mu$, we have\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( \\mu, \\Lambda \\mid \\{x_n\\}_{n=1}^N, v, W, m, \\kappa) + \\mbox{const} \n",
      "&= \\frac{1}{2} \\log |\\Lambda| + \\frac{N + v - D - 1}{2} \\log |\\Lambda|\n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\\\ &\\quad\n",
      "  - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)  - \\frac{1}{2} \\sum_{n=1}^N(x_n - \\mu)^T \\Lambda (x_n - \\mu)\n",
      "\\end{align}\n",
      "\n",
      "Now, we simplify the quadratic forms. Let $Q = \\sum_{n=1}^N x_n x_n^T$. $s = \\frac{1}{N}\\sum_{n=1}^N x_n$.\n",
      "\n",
      "\\begin{align}\n",
      "\\sum_{n=1}^N(x_n - \\mu)^T \\Lambda (x_n - \\mu) \n",
      "&= \\mbox{tr}\\Big( \\Lambda \\sum_{n=1}^N x_n x_n^T  \\Big) - 2 (\\sum_{n=1}^N x_n)^T \\Lambda \\mu + N \\mu^T \\Lambda \\mu\n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( \\Lambda Q \\Big) - 2 (Ns)^T \\Lambda \\mu + N \\mu^T \\Lambda \\mu\n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( \\Lambda Q \\Big) + N \\Big[ - 2 s^T \\Lambda \\mu + \\mu^T \\Lambda \\mu \\Big] \n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( \\Lambda Q \\Big) + N \\Big[ s^T \\Lambda s - 2 s^T \\Lambda \\mu + \\mu^T \\Lambda \\mu \\Big] - N s^T \\Lambda s\n",
      "\\\\\n",
      "&= \\mbox{tr}\\Big( \\Lambda (Q - N s s^T) \\Big) + N (s - \\mu)^T \\Lambda (s - \\mu)\n",
      "\\end{align}\n",
      "\n",
      "Next, we can simplify the *combined* quadratic form\n",
      "\n",
      "\\begin{align}\n",
      "~ \\kappa (\\mu - m)^T \\Lambda (\\mu - m)  + \\Big[ \\sum_{n=1}^N(x_n - \\mu)^T \\Lambda (x_n - \\mu) \\Big] - \\mbox{tr}\\Big( \\Lambda (Q - N s s^T) \\Big) \n",
      "&= \\kappa (\\mu - m)^T \\Lambda (\\mu - m)  + N (s - \\mu)^T \\Lambda (s - \\mu) \n",
      "\\\\\n",
      "&= \\kappa \\mu^T \\Lambda \\mu - 2 \\kappa m^T \\Lambda \\mu + \\kappa \\mbox{tr}(\\Lambda m m^T)\n",
      "\\\\ &\\quad \n",
      "   + N \\mu^T \\Lambda \\mu - 2 N s^T \\Lambda \\mu + N \\mbox{tr}( \\Lambda s s^T )\n",
      "\\\\\n",
      "&= (\\kappa + N) \\mu^T \\Lambda \\mu - 2 (\\kappa m + N s) \\Lambda \\mu + \\mbox{tr}(\\Lambda (\\kappa m m^T + N s s^T) )\n",
      "\\\\\n",
      "&= \\Big[ \\kappa_N \\mu^T \\Lambda \\mu - 2 \\kappa_N m_N \\Lambda \\mu + \\kappa_N m_N^T \\Lambda m_N \\Big] \n",
      "\\\\ &\\quad - \\kappa_N m_N^T \\Lambda m_N  + \\mbox{tr}(\\Lambda (\\kappa m m^T + N s s^T) )\n",
      "\\\\\n",
      "&= \\Big[ \\kappa_N (\\mu - m_N)^T \\Lambda (\\mu - m_N) \\Big] + \\mbox{tr}\\Big(\\Lambda (\\kappa m m^T + N s s^T - \\kappa_N m_N m_N^T )  \\Big)\n",
      "\\end{align}\n",
      "\n",
      "We thus arrive a simplified form\n",
      "\\begin{align}\n",
      "~ \\kappa (\\mu - m)^T \\Lambda (\\mu - m)  + \\Big[ \\sum_{n=1}^N(x_n - \\mu)^T \\Lambda (x_n - \\mu) \\Big]\n",
      "&= \\Big[ \\kappa_N (\\mu - m_N)^T \\Lambda (\\mu - m_N) \\Big] +  \\mbox{tr}\\Big( \\Lambda (Q + \\kappa m m^T - \\kappa_N m_N m_N^T )  \\Big)\n",
      "\\end{align}\n",
      "\n",
      "Returning finally to our log posterior, we have\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( \\mu, \\Lambda \\mid \\{x_n\\}_{n=1}^N, v, W, m, \\kappa) + \\mbox{const} \n",
      "&= \\frac{1}{2} \\log |\\Lambda| + \\frac{N + v - D - 1}{2} \\log |\\Lambda|\n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda ( W^{-1} + Q + \\kappa m m^T - \\kappa_N m_N m_N^T ) \\Big)\n",
      "\\\\ &\\quad +\n",
      " -\\frac{1}{2} \\kappa_N (\\mu - m_N)^T \\Lambda (\\mu - m_N)  \n",
      "\\end{align}\n",
      "\n",
      "Which by inspection, we recognize as a Gaussian-Wishart distribution with mean $m_N$, precision $\\kappa_N$, scale matrix $W_N$, and degrees-of-freedom $v_N$, where\n",
      "\n",
      "\\begin{align}\n",
      "v_N &= v + N\n",
      "\\\\\n",
      "W_N^{-1} &= W^{-1} + \\sum_{n=1}^N x_n x_n^T + \\kappa m m^T - \\kappa_N m_N m_N^T \n",
      "\\\\\n",
      "\\kappa_N &= \\kappa + N\n",
      "\\\\\n",
      "m_N &= \\frac{\\kappa m + \\sum_{n=1}^N x_n}{\\kappa + N}\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## OLD STUFF BELOW HERE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{align}\n",
      "\\\\\n",
      "&= \\mbox{const}  \n",
      "   + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)\n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "  + \\frac{N}{2} \\log |\\Lambda| - \\frac{1}{2} \\sum_{n=1}^N (x_n - \\mu)^T \\Lambda (x_n - \\mu)\n",
      "\\\\\n",
      "&= \\mbox{const}\n",
      "   + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)\n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\\\ &\\quad\n",
      "  + \\frac{N}{2} \\log |\\Lambda| \n",
      "  - \\frac{1}{2} \\mbox{tr}\\Big( \\Lambda Q - S^T \\Lambda \\mu - \\mu^T \\Lambda S + N \\Lambda \\mu \\mu^T  \\Big)\n",
      "\\\\\n",
      "&= \\mbox{const}\n",
      "   + \\frac{1}{2} \\log |\\Lambda| - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m)\n",
      "  + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda W^{-1} \\Big)\n",
      "\\\\ &\\quad\n",
      "  + \\frac{N}{2} \\log |\\Lambda| \n",
      "  - \\frac{1}{2} \\mbox{tr}\\Big( \\Lambda (Q - N\\bar{s}\\bar{s}^T) \\Big) - \\frac{1}{2} N (\\bar{s} - \\mu)^T \\Lambda (\\bar{s} - \\mu)  \\Big)\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\\begin{align}\n",
      "&= \\mbox{const}\n",
      "   + \\frac{1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  + \\frac{N + v - D - 1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda (W^{-1} + Q - N\\bar{s}\\bar{s}^T) \\Big)\n",
      "\\\\ &\\quad\n",
      "  - \\frac{\\kappa}{2} (\\mu - m)^T \\Lambda (\\mu - m) - \\frac{N}{2} (\\bar{s} - \\mu)^T \\Lambda (\\bar{s} - \\mu)  \\Big)\n",
      "\\\\ %%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "&= \\mbox{const}\n",
      "   + \\frac{1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  + \\frac{N + v - D - 1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda (W^{-1} + Q - N\\bar{s}\\bar{s}^T) \\Big)\n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\kappa_N (\\mu - m_N)^T \\Lambda (\\mu - m_N) + \\frac{1}{2} \\mbox{tr}\\Big( \\Lambda \\kappa_N m_N m_N^T \\Big)\n",
      "\\\\ %%%%%%%%%%%%%%%%%%%%%%%%%%  \n",
      "&= \\mbox{const}\n",
      "   + \\frac{1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  + \\frac{N + v - D - 1}{2} \\log |\\Lambda| \n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda (W^{-1} + Q - N\\bar{s}\\bar{s}^T - \\kappa_N m_N m_N^T ) \\Big)\n",
      "\\\\ &\\quad\n",
      "  - \\frac{1}{2} \\kappa_N (\\mu - m_N)^T \\Lambda (\\mu - m_N)\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Simplify big trace expression\n",
      "\n",
      "\\begin{align}\n",
      "&~~ \\mbox{tr}\\Big( - s^T \\Lambda \\mu - \\mu^T \\Lambda s + N \\Lambda \\mu \\mu^T  \\Big)\n",
      "\\\\\n",
      "&= N \\mbox{tr}\\Big( - \\bar{s}^T \\Lambda \\mu - \\mu^T \\Lambda \\bar{s} + \\Lambda \\mu \\mu^T  \\Big)\n",
      "\\\\\n",
      "&= N \\mbox{tr}\\Big( \\bar{s}^T \\Lambda \\bar{s} - \\bar{s}^T \\Lambda \\mu - \\mu^T \\Lambda \\bar{s} + \\Lambda \\mu \\mu^T  \\Big) - N \\bar{s}^T \\Lambda \\bar{s}\n",
      "\\\\\n",
      "&= N (\\bar{s} - \\mu)^T \\Lambda (\\bar{s} - \\mu) - N \\bar{s}^T \\Lambda \\bar{s}\n",
      "\\\\\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Combine all quadratic form terms\n",
      "\n",
      "\\begin{align}\n",
      "& = \\kappa (\\mu - m)^T \\Lambda (\\mu-m) + N (s - \\mu) \\Lambda (s - \\mu)\n",
      "\\\\\n",
      "& = \\kappa \\mbox{tr}\\Big( \\Lambda \\mu \\mu^T - 2 m^T \\Lambda \\mu + \\Lambda m m^T \\Big)\n",
      "\\\\\n",
      "&\\quad + N \\mbox{tr} \\Big( \\Lambda \\mu \\mu^T - 2 s^T \\Lambda \\mu + \\Lambda s s^T \\Big)\n",
      "\\\\\n",
      "& = (\\kappa + N) \\mu^T \\Lambda \\mu  - 2 (\\kappa m + N s)^T \\Lambda \\mu  + \\mbox{tr}\\Big( \\Lambda (\\kappa m m^T + N s s^T) \\Big)\n",
      "\\end{align}\n",
      "\n",
      "Complete the square! \n",
      "\n",
      "* Here's the pattern\n",
      "\\begin{align}\n",
      "k_N (\\mu - m_N) \\Lambda ( \\mu - m_N)\n",
      "&= k_N \\mu^T \\Lambda \\mu - 2 k_N m_N^T \\Lambda \\mu + k_N m_N^T \\Lambda m_N\n",
      "\\end{align}\n",
      "\n",
      "* Here's the implementation. Let $\\kappa_N = \\kappa + N$, $m_N = \\frac{\\kappa m + N s}{\\kappa + N}$.\n",
      "\n",
      "\\begin{align}\n",
      "&= (\\kappa + N) \\mu^T \\Lambda \\mu - 2 (\\kappa m + N s)^T \\Lambda \\mu \n",
      "\\\\\n",
      "&= \\kappa_N \\mu^T \\Lambda \\mu - 2 \\kappa_N m_N^T \\Lambda \\mu \n",
      "\\\\\n",
      "&= \\kappa_N \\mu^T \\Lambda \\mu - 2 \\kappa_N m_N^T \\Lambda \\mu + \\kappa_N m_N^T \\Lambda m_N - \\kappa_N m_N^T \\Lambda m_N\n",
      "\\\\\n",
      "&= \\kappa_N (\\mu - m_N) \\Lambda (\\mu - m_N) - \\kappa_N \\mbox{tr}\\Big( \\Lambda m_N m_N^T \\Big)\n",
      "\\end{align}\n",
      "\n",
      "## Return to original"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}