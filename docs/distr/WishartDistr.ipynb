{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Wishart\n",
      "\n",
      "## Goal\n",
      "\n",
      "Describes a **bnpy** Distr object: the Wishart distribution with $D$ dimensions. \n",
      "\n",
      "The Wishart is a multivariate generalization of the Gamma distribution, and a useful prior for learning convariance matrices.\n",
      "\n",
      "## Basic Notation\n",
      "\n",
      "$$\n",
      "\\Lambda \\sim \\mbox{Wishart}( \\Lambda \\mid v, W)\n",
      "$$\n",
      "\n",
      "equivalently\n",
      "\n",
      "$$\n",
      "\\Lambda^{-1} \\sim \\mbox{InverseWishart}( \\cdot \\mid v, W^{-1} )\n",
      "$$\n",
      "\n",
      "### Parameters\n",
      "$D \\times D$ matrix $\\Lambda$ is symmetric and positive (semi-) definite.\n",
      "\n",
      "### Hyperparameters\n",
      "\n",
      "The Wishart distribution is specified by a scalar $v$ and a $D \\times D$ matrix $W$.\n",
      "\n",
      "Scalar $v$ is always positive, and represents the degrees-of-freedom.\n",
      "\n",
      "Matrix $W$ is always symmetric and positive definite.\n",
      "\n",
      "### Generating Data\n",
      "\n",
      "Each observated data point $x$ is a $D$-dimensional vector. \n",
      "\n",
      "We sample $x$ from a normal distribution with fixed mean (the vector of all zeros), and precision matrix $\\Lambda$.\n",
      "$$\n",
      "x \\sim \\mbox{Normal}( x \\mid 0, \\Lambda^{-1} )\n",
      "$$\n",
      "equivalently, if we define $\\Sigma = \\Lambda^{-1}$, then\n",
      "$$\n",
      "x \\sim \\mbox{Normal}( x \\mid 0, \\Sigma )\n",
      "$$\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Useful moments\n",
      "\n",
      "#### Expected value of matrix $\\Lambda$\n",
      "\\begin{align}\n",
      "\\mbox{E}[ \\Lambda ] = v W\n",
      "\\end{align}\n",
      "\n",
      "#### Expected value of matrix $\\Sigma = \\Lambda^{-1}$\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[ \\Sigma ] \\triangleq \\mbox{E}[ \\Lambda^{-1} ] = \\frac{W^{-1}}{v - D - 1}\n",
      "\\end{align}\n",
      "\n",
      "#### Expected mahalonobis distance\n",
      "\n",
      "For a $D$-length vector $x$, we have\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[ x^T \\Lambda x ] \n",
      "&= \\mbox{E}[ \\mbox{tr}(\\Lambda x x^T) ]\n",
      "\\\\\n",
      "&= \\mbox{tr}( \\mbox{E}[\\Lambda] x x^T )\n",
      "\\\\\n",
      "&= v ~\\mbox{tr}( W x x^T )\n",
      "\\end{align}\n",
      "\n",
      "#### Expected value of log determinant: $\\log |\\Lambda |$\n",
      "According to Bishop B.81\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[ \\log |\\Lambda_d| ] \n",
      "&= D \\log 2 + \\log |W| + \\psi_D(\\frac{v}{2})\n",
      "\\end{align}\n",
      "\n",
      "where\n",
      "\\begin{align}\n",
      "\\psi_D(a) = \\sum_{d=1}^D \\psi(a + \\frac{ 1 - d}{2}) \n",
      "\\end{align}\n",
      "\n",
      "#### Entropy of the Wishart\n",
      "\n",
      "According to Bishop B.83\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{H}[\\Lambda] = - \\log Z(v, W) - \\frac{v - D - 1}{2} \\mbox{E}[ \\log | \\Lambda |] + \\frac{vD}{2}\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LOG PDF \n",
      "\n",
      "### Log probability density function of Wishart Distribution\n",
      "\n",
      "\\begin{align}\n",
      "\\log p(\\Lambda) &= - \\log Z(v,W) + \\frac{v - D - 1}{2} \\log |\\Lambda | - \\frac{1}{2} \\mbox{tr}(W^{-1} \\Lambda)\n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Log normalization constant of Wishart Distribution\n",
      "\n",
      "\\begin{align}\n",
      "\\log Z(v, W) &= \\frac{vD}{2} \\log 2 + \\log \\Gamma_D(\\frac{v}{2}) - \\frac{v}{2} \\log |W^{-1}|\n",
      "\\\\\n",
      "&=  \\frac{vD}{2} \\log 2 + \\log \\Gamma_D(\\frac{v}{2}) + \\frac{v}{2} \\log |W|\n",
      "\\end{align}\n",
      "\n",
      "Remember there is always a reciprocal relationship between determinants of matrix inverses\n",
      "$$\n",
      "|W^{-1}| = \\frac{1}{|W|}\n",
      "$$\n",
      "so we can equivalently use either line above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Expected log pdf of Wishart\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\log p(\\Lambda | v_0, W_0)]\n",
      "&= - \\log Z(v_0,W_0) + \\frac{v_0 - D - 1}{2} \\mbox{E}[\\log |\\Lambda |] - \\frac{1}{2} \\mbox{tr}(W_0^{-1} \\mbox{E}[\\Lambda])\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## LOG LIKELIHOOD \n",
      "\n",
      "Here we study the log pdf of the data-generating distribution.\n",
      "\n",
      "\\begin{align}\n",
      "\\log p( x_n | \\Lambda)\n",
      "&= \\log \\mbox{Normal}( x_n \\mid 0, \\Lambda )\n",
      "\\\\\n",
      "&= - \\frac{D}{2} \\log [2\\pi] + \\frac{1}{2} \\log |\\Lambda| - \\frac{1}{2} x_n^T \\Lambda^{-1} x_n \n",
      "\\end{align}\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Expected Log Likelihood\n",
      "\n",
      "Under a single distribution, we can find the expected log probability as follows, using the basic expectations defined above\n",
      "\n",
      "\\begin{align}\n",
      "\\mbox{E}[\\log p(x_n | \\Lambda) ]\n",
      "&= - \\frac{D}{2} \\log [2\\pi] + \\frac{1}{2} \\mbox{E}[\\log |\\Lambda|] - \\frac{1}{2} \\mbox{E}\\Big[ x_n^T \\Lambda x_n \\Big]\n",
      "\\\\\n",
      "&= - \\frac{D}{2} \\log [2\\pi] + \\frac{1}{2} \\mbox{E}[\\log |\\Lambda|] - \\frac{1}{2}  \\mbox{tr}(\\mbox{E}[\\Lambda] x_n x_n^T)\n",
      "\\end{align}\n",
      "\n",
      "This derivation relies on the commutivity of the trace operator: $\\mbox{tr}(ABC) = \\mbox{tr}(BCA)$, and the expected mahalanobis distance defined above."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Posterior updates\n",
      "\n",
      "After seeing $N$ data items, we have the following posterior distribution\n",
      "\n",
      "\\begin{align}\n",
      "\\log p(\\Lambda | x, v, W) \n",
      "&= \\log p(\\Lambda | v, W) + \\sum_{n=1}^N \\log p( x_n | \\Lambda)\n",
      "\\\\\n",
      "&= - \\log Z(v, W) + \\frac{v - D - 1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr}(\\Lambda W^{-1}) \n",
      "\\\\\n",
      "&\\quad + \\frac{ND}{2} \\log [2\\pi] + \\frac{N}{2} \\log |\\Lambda| - \\frac{1}{2} \\sum_{n=1}^N \\mbox{tr}(\\Lambda x_n x_n^T )\n",
      "\\\\\n",
      "&= \\mbox{const} + \\frac{N+ v -D -1}{2} \\log |\\Lambda| - \\frac{1}{2} \\mbox{tr} \\Big( \\Lambda (W^{-1} + \\sum_{n=1}^N x_n x_n^T)\\Big)\n",
      "\\end{align}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here, we drop terms constant with respect to $\\Lambda$, our parameter of interest.\n",
      "\n",
      "By inspection, this log posterior has the form of a Wishart distribution, with parameters\n",
      "\n",
      "$$\n",
      "v_N = v + N\n",
      "\\\\\n",
      "W_N^{-1} = W^{-1} + \\sum_{n=1}^N x_n x_n^T\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}