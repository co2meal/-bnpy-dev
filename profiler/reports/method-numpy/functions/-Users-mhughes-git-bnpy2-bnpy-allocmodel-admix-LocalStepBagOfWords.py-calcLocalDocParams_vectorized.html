<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Profiling Results</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Bootstrap -->
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/docs.css" rel="stylesheet">
    <link rel="stylesheet" href="/Users/mhughes/git/bnpy2/profile/assets/css/font-awesome/font-awesome.min.css">
  </head>

  <body id="top">
    <header class="navbar navbar-inverse navbar-static-top bs-docs-nav" role="banner">
      <div class="container">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a href="../index.html" class="navbar-brand">Profiling Results</a>
        </div>
        <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li>
              <a href="../index.html">Summary</a>
            </li>
            <li class="active">
              <a href="#">calcLocalDocParams_vectorized</a>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <div class="container bs-docs-container">
      <div class="row">
	<div class="col-md-2">
	  <div class="bs-sidebar affix-top hidden-print" role="complementary">
	    <ul class="nav bs-sidenav">
              <li><a href="#function">calcLocalDocParams_vectorized</a></li>
	      <!-- <li><a href="#parents">Parents</a></li> -->
	      <!-- <li><a href="#children">Possible Children</a></li> -->
	      <li><a href="#listing">Function Listing</a></li>
	    </ul>

	  </div>
	</div>
        <div class="col-md-10">
	  <div class="page-header" id="function">
	    <h1>calcLocalDocParams_vectorized</h1>
	  </div>

          <p>1177875 Calls, 65.32 s</p>
	  <p>Generated 16:17:14 04/27/14 EDT</p>
          <p>Function in file <a href="/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/LocalStepBagOfWords.py">/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/LocalStepBagOfWords.py</a></p>

          <h3 id="listing">Function listing</h3>
          <table class="table table-borderless table-condensed">
            <tr>
              <th>time</th>
              <th>calls</th>
              <th>line</th>
              <th>code</th>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line69">69</td>
              <td><pre>@profile</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line70">70</td>
              <td><pre>def calcLocalDocParams_vectorized(Data, LP, topicPrior, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line71">71</td>
              <td><pre>                             unusedTopicPrior=None,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line72">72</td>
              <td><pre>                             nCoordAscentItersLP=20,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line73">73</td>
              <td><pre>                             convThrLP=0.01,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line74">74</td>
              <td><pre>                             doUniformFirstTime=False, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line75">75</td>
              <td><pre>                             **kwargs):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line76">76</td>
              <td><pre>  ''' Returns </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line77">77</td>
              <td><pre>      -------</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line78">78</td>
              <td><pre>      LP : dictionary with fields</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line79">79</td>
              <td><pre>           theta : 2D array, size nDoc x K</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line80">80</td>
              <td><pre>           ElogPi : 2D array, size nDoc x K</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line81">81</td>
              <td><pre>           unusedElogPi : 1D array, size nDoc</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line82">82</td>
              <td><pre>  '''</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line83">83</td>
              <td><pre>  K = topicPrior.size</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line84">84</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line85">85</td>
              <td><pre>  # Precompute ONCE exp( E_logsoftev ), in-place</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line86">86</td>
              <td><pre>  expEloglik = LP['E_logsoftev_WordsData']</pre></td>
            </tr>
            
            <tr class="">
              <td> 1.91 s</td>
              <td>598</td>
              <td id="line87">87</td>
              <td><pre>  expEloglik -= expEloglik.max(axis=1)[:,np.newaxis] </pre></td>
            </tr>
            
            <tr class="">
              <td> 3.90 s</td>
              <td>598</td>
              <td id="line88">88</td>
              <td><pre>  NumericUtil.inplaceExp(expEloglik)  </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line89">89</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line90">90</td>
              <td><pre>  ######## Allocate document-specific variables</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>598</td>
              <td id="line91">91</td>
              <td><pre>  LP['DocTopicCount'] = np.zeros((Data.nDoc, K))</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line92">92</td>
              <td><pre>  if 'theta' in LP and LP['theta'].shape[1] == K:</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line93">93</td>
              <td><pre>    LP = update_ElogPi(LP, unusedTopicPrior)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line94">94</td>
              <td><pre>  else:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line95">95</td>
              <td><pre>    LP['theta'] = np.zeros((Data.nDoc, K))</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line96">96</td>
              <td><pre>    doUniformFirstTime = True</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line97">97</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line98">98</td>
              <td><pre>  ######## Allocate token-specific variables</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line99">99</td>
              <td><pre>  # sumRTilde : nDistinctWords-length vector of reals</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line100">100</td>
              <td><pre>  #   row n = \sum_{k} \tilde{r}_{nk}, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line101">101</td>
              <td><pre>  #             where \tilde{r}_nk = \exp{ Elog[\pi_d] + Elog[\phi_dvk] }</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line102">102</td>
              <td><pre>  #   each entry is the "normalizer" for each row of LP['resp']</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.02 s</td>
              <td>598</td>
              <td id="line103">103</td>
              <td><pre>  sumRTilde = np.zeros(Data.nObs)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line104">104</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line105">105</td>
              <td><pre>  ######## Repeat updates until old_theta has stopped changing ...</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line106">106</td>
              <td><pre>  activeDocs = range(Data.nDoc)</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line107">107</td>
              <td><pre>  old_theta = LP['theta'].copy()</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.02 s</td>
              <td>10020</td>
              <td id="line108">108</td>
              <td><pre>  for ii in xrange(nCoordAscentItersLP):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line109">109</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line110">110</td>
              <td><pre>    # Update expElogpi for active documents</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.02 s</td>
              <td>9424</td>
              <td id="line111">111</td>
              <td><pre>    if doUniformFirstTime and ii == 0:</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>598</td>
              <td id="line112">112</td>
              <td><pre>      expElogpi = np.ones((Data.nDoc, K))</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line113">113</td>
              <td><pre>    else:</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.03 s</td>
              <td>8826</td>
              <td id="line114">114</td>
              <td><pre>      if len(activeDocs) == Data.nDoc:</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.27 s</td>
              <td>6938</td>
              <td id="line115">115</td>
              <td><pre>        expElogpi = np.exp(LP['E_logPi'])</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line116">116</td>
              <td><pre>      else:</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.18 s</td>
              <td>1888</td>
              <td id="line117">117</td>
              <td><pre>        expElogpi[activeDocs] = np.exp(LP['E_logPi'][activeDocs])    </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line118">118</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td> 3.35 s</td>
              <td>1177875</td>
              <td id="line119">119</td>
              <td><pre>    for d in activeDocs:</pre></td>
            </tr>
            
            <tr class="">
              <td> 3.93 s</td>
              <td>1168451</td>
              <td id="line120">120</td>
              <td><pre>      start = Data.doc_range[d,0]</pre></td>
            </tr>
            
            <tr class="">
              <td> 3.60 s</td>
              <td>1168451</td>
              <td id="line121">121</td>
              <td><pre>      stop  = Data.doc_range[d,1]</pre></td>
            </tr>
            
            <tr class="">
              <td> 3.49 s</td>
              <td>1168451</td>
              <td id="line122">122</td>
              <td><pre>      expEloglik_d = expEloglik[start:stop]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line123">123</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td> 12.87 s</td>
              <td>1168451</td>
              <td id="line124">124</td>
              <td><pre>      np.dot(expEloglik_d, expElogpi[d], out=sumRTilde[start:stop])</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line125">125</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td> 11.01 s</td>
              <td>1168451</td>
              <td id="line126">126</td>
              <td><pre>      np.dot(Data.word_count[start:stop] / sumRTilde[start:stop],</pre></td>
            </tr>
            
            <tr class="">
              <td> 2.53 s</td>
              <td>1168451</td>
              <td id="line127">127</td>
              <td><pre>               expEloglik_d,</pre></td>
            </tr>
            
            <tr class="danger">
              <td> 13.06 s</td>
              <td>1168451</td>
              <td id="line128">128</td>
              <td><pre>               out=LP['DocTopicCount'][d,:]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line129">129</td>
              <td><pre>            )</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line130">130</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td> 0.02 s</td>
              <td>9424</td>
              <td id="line131">131</td>
              <td><pre>    if not (doUniformFirstTime and ii == 0):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line132">132</td>
              <td><pre>      # Element-wise multiply with nDoc x K prior prob matrix</pre></td>
            </tr>
            
            <tr class="">
              <td> 1.15 s</td>
              <td>8826</td>
              <td id="line133">133</td>
              <td><pre>      LP['DocTopicCount'][activeDocs] *= expElogpi[activeDocs]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line134">134</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line135">135</td>
              <td><pre>    # Update theta</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.22 s</td>
              <td>9424</td>
              <td id="line136">136</td>
              <td><pre>    LP['theta'] = LP['DocTopicCount'] + topicPrior[np.newaxis,:]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line137">137</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line138">138</td>
              <td><pre>    # Update expected value of log Pi[d,k]</pre></td>
            </tr>
            
            <tr class="">
              <td> 2.80 s</td>
              <td>9424</td>
              <td id="line139">139</td>
              <td><pre>    LP = update_ElogPi(LP, unusedTopicPrior)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line140">140</td>
              <td><pre>    </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line141">141</td>
              <td><pre>    # Assess convergence</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.43 s</td>
              <td>9424</td>
              <td id="line142">142</td>
              <td><pre>    docDiffs = np.max(np.abs(old_theta - LP['theta']), axis=1)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.20 s</td>
              <td>9424</td>
              <td id="line143">143</td>
              <td><pre>    if np.max(docDiffs) < convThrLP:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line144">144</td>
              <td><pre>      break</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.17 s</td>
              <td>9422</td>
              <td id="line145">145</td>
              <td><pre>    activeDocs = np.flatnonzero(docDiffs > convThrLP)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line146">146</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line147">147</td>
              <td><pre>    # Store previous value of theta for next round's convergence test</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line148">148</td>
              <td><pre>    # Here, the "[:]" syntax ensures we do NOT copy the pointer</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.06 s</td>
              <td>9422</td>
              <td id="line149">149</td>
              <td><pre>    old_theta[:] = LP['theta']</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line150">150</td>
              <td><pre>    ### end loop over alternating-ascent updates</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line151">151</td>
              <td><pre>  </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line152">152</td>
              <td><pre>  ######## </pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line153">153</td>
              <td><pre>  if unusedTopicPrior is not None:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line154">154</td>
              <td><pre>    LP['theta_u'] = unusedTopicPrior</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line155">155</td>
              <td><pre>    LP['E_logPi_u'] = digamma(unusedTopicPrior) - LP['digammasumTheta']</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line156">156</td>
              <td><pre>  LP['sumRTilde'] = sumRTilde</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line157">157</td>
              <td><pre>  LP['expElogpi'] = expElogpi</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line158">158</td>
              <td><pre>  LP['expEloglik'] = expEloglik</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line159">159</td>
              <td><pre>  del LP['E_logsoftev_WordsData']</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line160">160</td>
              <td><pre>  assert 'digammasumTheta' in LP</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>598</td>
              <td id="line161">161</td>
              <td><pre>  return LP</pre></td>
            </tr>
            
          </table>
        </div>
      </div>
    </div>

    <a href="#top" class="scrollToTop hidden-phone" >
      <i class="icon-chevron-up"></i>
    </a>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/bootstrap.min.js"></script>
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/main.js"></script>

  </body>
</html>
