<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Profiling Results</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Bootstrap -->
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/docs.css" rel="stylesheet">
    <link rel="stylesheet" href="/Users/mhughes/git/bnpy2/profile/assets/css/font-awesome/font-awesome.min.css">
  </head>

  <body id="top">
    <header class="navbar navbar-inverse navbar-static-top bs-docs-nav" role="banner">
      <div class="container">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a href="../index.html" class="navbar-brand">Profiling Results</a>
        </div>
        <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li>
              <a href="../index.html">Summary</a>
            </li>
            <li class="active">
              <a href="#">CreateToyDataFromLDAModel</a>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <div class="container bs-docs-container">
      <div class="row">
	<div class="col-md-2">
	  <div class="bs-sidebar affix-top hidden-print" role="complementary">
	    <ul class="nav bs-sidenav">
              <li><a href="#function">CreateToyDataFromLDAModel</a></li>
	      <!-- <li><a href="#parents">Parents</a></li> -->
	      <!-- <li><a href="#children">Possible Children</a></li> -->
	      <li><a href="#listing">Function Listing</a></li>
	    </ul>

	  </div>
	</div>
        <div class="col-md-10">
	  <div class="page-header" id="function">
	    <h1>CreateToyDataFromLDAModel</h1>
	  </div>

          <p>44000 Calls, 3.78 s</p>
	  <p>Generated 23:15:55 06/03/14 EDT</p>
          <p>Function in file <a href="/Users/mhughes/git/bnpy2/bnpy/data/WordsData.py">/Users/mhughes/git/bnpy2/bnpy/data/WordsData.py</a></p>

          <h3 id="listing">Function listing</h3>
          <table class="table table-borderless table-condensed">
            <tr>
              <th>time</th>
              <th>calls</th>
              <th>line</th>
              <th>code</th>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line603">603</td>
              <td><pre> @classmethod</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line604">604</td>
              <td><pre> @profile</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line605">605</td>
              <td><pre> def CreateToyDataFromLDAModel(cls, seed=101, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line606">606</td>
              <td><pre>               nDocTotal=None, nWordsPerDoc=None, nWordsPerDocFunc=None,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line607">607</td>
              <td><pre>               topic_prior=None, topics=None,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line608">608</td>
              <td><pre>               **kwargs):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line609">609</td>
              <td><pre>   ''' Generates WordsData dataset via LDA generative model,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line610">610</td>
              <td><pre>         given specific global parameters</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line611">611</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line612">612</td>
              <td><pre>       Args</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line613">613</td>
              <td><pre>       --------</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line614">614</td>
              <td><pre>       topic_prior : K-length vector of positive reals,</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line615">615</td>
              <td><pre>                     \pi_d \sim \Dir( topic_prior )</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line616">616</td>
              <td><pre>       topics : KxV matrix of positive reals, where rows sum to one</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line617">617</td>
              <td><pre>                 topics[k,v] := probability of vocab word v in topic k</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line618">618</td>
              <td><pre>   '''</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line619">619</td>
              <td><pre>   PRNG = np.random.RandomState(seed)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line620">620</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line621">621</td>
              <td><pre>   K = topics.shape[0]</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line622">622</td>
              <td><pre>   V = topics.shape[1]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line623">623</td>
              <td><pre>   # Make sure topics sum to one</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line624">624</td>
              <td><pre>   topics = topics / topics.sum(axis=1)[:,np.newaxis]</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line625">625</td>
              <td><pre>   assert K == topic_prior.size</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line626">626</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line627">627</td>
              <td><pre>   doc_range = np.zeros((nDocTotal, 2))</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line628">628</td>
              <td><pre>   wordIDsPerDoc = list()</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line629">629</td>
              <td><pre>   wordCountsPerDoc = list()</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line630">630</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line631">631</td>
              <td><pre>   alphaLP = np.zeros((nDocTotal,K))</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line632">632</td>
              <td><pre>   respPerDoc = list()</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line633">633</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line634">634</td>
              <td><pre>   # startPos : tracks start index for current doc within corpus-wide lists</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line635">635</td>
              <td><pre>   startPos = 0</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>4002</td>
              <td id="line636">636</td>
              <td><pre>   for d in xrange(nDocTotal):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line637">637</td>
              <td><pre>     # Draw topic appearance probabilities for this document</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.04 s</td>
              <td>4000</td>
              <td id="line638">638</td>
              <td><pre>     alphaLP[d,:] = PRNG.dirichlet(topic_prior)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line639">639</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>4000</td>
              <td id="line640">640</td>
              <td><pre>     if nWordsPerDocFunc is not None:</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line641">641</td>
              <td><pre>       nWordsPerDoc = nWordsPerDocFunc(PRNG)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line642">642</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line643">643</td>
              <td><pre>     # Draw the topic assignments for this doc</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line644">644</td>
              <td><pre>     ## Npercomp : K-vector, Npercomp[k] counts appearance of topic k</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.12 s</td>
              <td>4000</td>
              <td id="line645">645</td>
              <td><pre>     Npercomp = RandUtil.multinomial(nWordsPerDoc, alphaLP[d,:], PRNG)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line646">646</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line647">647</td>
              <td><pre>     # Draw the observed words for this doc</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line648">648</td>
              <td><pre>     ## wordCountBins: V x 1 vector, entry v counts appearance of word v</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.02 s</td>
              <td>4000</td>
              <td id="line649">649</td>
              <td><pre>     wordCountBins = np.zeros(V)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.10 s</td>
              <td>44000</td>
              <td id="line650">650</td>
              <td><pre>     for k in xrange(K):</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.10 s</td>
              <td>40000</td>
              <td id="line651">651</td>
              <td><pre>       wordCountBins += RandUtil.multinomial(Npercomp[k], </pre></td>
            </tr>
            
            <tr class="danger">
              <td> 2.41 s</td>
              <td>40000</td>
              <td id="line652">652</td>
              <td><pre>                                     topics[k,:], PRNG)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line653">653</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line654">654</td>
              <td><pre>     # Record word_id, word_count, doc_range</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.07 s</td>
              <td>4000</td>
              <td id="line655">655</td>
              <td><pre>     wIDs = np.flatnonzero(wordCountBins > 0)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.03 s</td>
              <td>4000</td>
              <td id="line656">656</td>
              <td><pre>     wCounts = wordCountBins[wIDs]</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.34 s</td>
              <td>4000</td>
              <td id="line657">657</td>
              <td><pre>     assert np.allclose( wCounts.sum(), nWordsPerDoc)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>4000</td>
              <td id="line658">658</td>
              <td><pre>     wordIDsPerDoc.append(wIDs)</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>4000</td>
              <td id="line659">659</td>
              <td><pre>     wordCountsPerDoc.append(wCounts)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>4000</td>
              <td id="line660">660</td>
              <td><pre>     doc_range[d,0] = startPos</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>4000</td>
              <td id="line661">661</td>
              <td><pre>     doc_range[d,1] = startPos + wIDs.size  </pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>4000</td>
              <td id="line662">662</td>
              <td><pre>     startPos += wIDs.size</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line663">663</td>
              <td><pre> </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line664">664</td>
              <td><pre>     # Record expected local parameters (LP)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.26 s</td>
              <td>4000</td>
              <td id="line665">665</td>
              <td><pre>     curResp = (topics[:, wIDs] * alphaLP[d,:][:,np.newaxis]).T      </pre></td>
            </tr>
            
            <tr class="">
              <td> 0.01 s</td>
              <td>4000</td>
              <td id="line666">666</td>
              <td><pre>     respPerDoc.append(curResp)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line667">667</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td> 0.03 s</td>
              <td>2</td>
              <td id="line668">668</td>
              <td><pre>   word_id = np.hstack(wordIDsPerDoc)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.03 s</td>
              <td>2</td>
              <td id="line669">669</td>
              <td><pre>   word_count = np.hstack(wordCountsPerDoc)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line670">670</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td> 0.06 s</td>
              <td>2</td>
              <td id="line671">671</td>
              <td><pre>   respLP = np.vstack(respPerDoc)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.09 s</td>
              <td>2</td>
              <td id="line672">672</td>
              <td><pre>   respLP /= respLP.sum(axis=1)[:,np.newaxis]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line673">673</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line674">674</td>
              <td><pre>   TrueParams = dict(K=K, topics=topics, beta=topic_prior,</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line675">675</td>
              <td><pre>                     word_variational=respLP, alphaPi=alphaLP)</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line676">676</td>
              <td><pre>   return WordsData(word_id, word_count, doc_range, V,</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>2</td>
              <td id="line677">677</td>
              <td><pre>                   nDocTotal=nDocTotal, TrueParams=TrueParams)</pre></td>
            </tr>
            
          </table>
        </div>
      </div>
    </div>

    <a href="#top" class="scrollToTop hidden-phone" >
      <i class="icon-chevron-up"></i>
    </a>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/bootstrap.min.js"></script>
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/main.js"></script>

  </body>
</html>
