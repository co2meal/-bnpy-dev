<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Profiling Results</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Bootstrap -->
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="/Users/mhughes/git/bnpy2/profile/assets/css/docs.css" rel="stylesheet">
    <link rel="stylesheet" href="/Users/mhughes/git/bnpy2/profile/assets/css/font-awesome/font-awesome.min.css">
  </head>

  <body id="top">
    <header class="navbar navbar-inverse navbar-static-top bs-docs-nav" role="banner">
      <div class="container">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a href="../index.html" class="navbar-brand">Profiling Results</a>
        </div>
        <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li>
              <a href="../index.html">Summary</a>
            </li>
            <li class="active">
              <a href="#">calc_local_params</a>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <div class="container bs-docs-container">
      <div class="row">
	<div class="col-md-2">
	  <div class="bs-sidebar affix-top hidden-print" role="complementary">
	    <ul class="nav bs-sidenav">
              <li><a href="#function">calc_local_params</a></li>
	      <!-- <li><a href="#parents">Parents</a></li> -->
	      <!-- <li><a href="#children">Possible Children</a></li> -->
	      <li><a href="#listing">Function Listing</a></li>
	    </ul>

	  </div>
	</div>
        <div class="col-md-10">
	  <div class="page-header" id="function">
	    <h1>calc_local_params</h1>
	  </div>

          <p>63720 Calls, 59.15 s</p>
	  <p>Generated 17:37:25 01/20/14 EST</p>
          <p>Function in file <a href="/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/HDPModel.py">/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/HDPModel.py</a></p>

          <h3 id="listing">Function listing</h3>
          <table class="table table-borderless table-condensed">
            <tr>
              <th>time</th>
              <th>calls</th>
              <th>line</th>
              <th>code</th>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line79">79</td>
              <td><pre>   @profile</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line80">80</td>
              <td><pre>   def calc_local_params(self, Data, LP, nCoordAscentItersLP=20, convThrLP=0.01, **kwargs):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line81">81</td>
              <td><pre>       ''' Calculate document-specific quantities (E-step)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line82">82</td>
              <td><pre>         Alternate updates to two terms until convergence</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line83">83</td>
              <td><pre>           (1) Approx posterior on topic-token assignment</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line84">84</td>
              <td><pre>                q(word_variational | word_token_variables)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line85">85</td>
              <td><pre>           (2) Approx posterior on doc-topic probabilities</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line86">86</td>
              <td><pre>                q(doc_variational | document_topic_variables)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line87">87</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line88">88</td>
              <td><pre>         Returns</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line89">89</td>
              <td><pre>         -------</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line90">90</td>
              <td><pre>         LP : local params dict, with fields</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line91">91</td>
              <td><pre>             Pi : nDoc x K+1 matrix, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line92">92</td>
              <td><pre>                row d has params for doc d's Dirichlet over K+1 topics</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line93">93</td>
              <td><pre>             word_variational : nDistinctWords x K matrix</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line94">94</td>
              <td><pre>                row i has params for word i's Discrete distr over K topics</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line95">95</td>
              <td><pre>             DocTopicCount : nDoc x K matrix</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line96">96</td>
              <td><pre>       '''</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line97">97</td>
              <td><pre>       # When given no prev. local params LP, need to initialize from scratch</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line98">98</td>
              <td><pre>       # this forces likelihood to drive the first round of local assignments</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>60</td>
              <td id="line99">99</td>
              <td><pre>       if 'alphaPi' not in LP:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>35</td>
              <td id="line100">100</td>
              <td><pre>           LP['alphaPi'] = np.ones((Data.nDoc,self.K+1))</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line101">101</td>
              <td><pre>       else:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>25</td>
              <td id="line102">102</td>
              <td><pre>           assert LP['alphaPi'].shape[1] == self.K + 1</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line103">103</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>60</td>
              <td id="line104">104</td>
              <td><pre>       LP = self.calc_ElogPi(LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>60</td>
              <td id="line105">105</td>
              <td><pre>       prevVec = LP['alphaPi'].flatten()</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line106">106</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line107">107</td>
              <td><pre>       # Allocate lots of memory once</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.67 s</td>
              <td>60</td>
              <td id="line108">108</td>
              <td><pre>       LP['word_variational'] = np.zeros(LP['E_logsoftev_WordsData'].shape)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line109">109</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line110">110</td>
              <td><pre>       # Repeat until converged...</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>696</td>
              <td id="line111">111</td>
              <td><pre>       for ii in xrange(nCoordAscentItersLP):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line112">112</td>
              <td><pre>           # Update word_variational field of LP</pre></td>
            </tr>
            
            <tr class="danger">
              <td> 55.01 s</td>
              <td>661</td>
              <td id="line113">113</td>
              <td><pre>           LP = self.get_word_variational(Data, LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line114">114</td>
              <td><pre>       </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line115">115</td>
              <td><pre>           # Update DocTopicCount field of LP</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>661</td>
              <td id="line116">116</td>
              <td><pre>           LP['DocTopicCount'] = np.zeros((Data.nDoc,self.K))</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.12 s</td>
              <td>63720</td>
              <td id="line117">117</td>
              <td><pre>           for d in xrange(Data.nDoc):</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.40 s</td>
              <td>63059</td>
              <td id="line118">118</td>
              <td><pre>               start,stop = Data.doc_range[d,:]</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.11 s</td>
              <td>63059</td>
              <td id="line119">119</td>
              <td><pre>               LP['DocTopicCount'][d,:] = np.dot(</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.15 s</td>
              <td>63059</td>
              <td id="line120">120</td>
              <td><pre>                                          Data.word_count[start:stop],        </pre></td>
            </tr>
            
            <tr class="">
              <td> 2.23 s</td>
              <td>63059</td>
              <td id="line121">121</td>
              <td><pre>                                          LP['word_variational'][start:stop,:]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line122">122</td>
              <td><pre>                                          )</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line123">123</td>
              <td><pre>           # Update doc_variational field of LP</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.07 s</td>
              <td>661</td>
              <td id="line124">124</td>
              <td><pre>           LP = self.get_doc_variational(Data, LP)</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.26 s</td>
              <td>661</td>
              <td id="line125">125</td>
              <td><pre>           LP = self.calc_ElogPi(LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line126">126</td>
              <td><pre></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line127">127</td>
              <td><pre>           # Assess convergence</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>661</td>
              <td id="line128">128</td>
              <td><pre>           curVec = LP['alphaPi'].flatten()</pre></td>
            </tr>
            
            <tr class="">
              <td> 0.10 s</td>
              <td>661</td>
              <td id="line129">129</td>
              <td><pre>           if np.allclose(prevVec, curVec, atol=convThrLP):</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>25</td>
              <td id="line130">130</td>
              <td><pre>               break</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>636</td>
              <td id="line131">131</td>
              <td><pre>           prevVec = curVec</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>60</td>
              <td id="line132">132</td>
              <td><pre>       return LP</pre></td>
            </tr>
            
          </table>
        </div>
      </div>
    </div>

    <a href="#top" class="scrollToTop hidden-phone" >
      <i class="icon-chevron-up"></i>
    </a>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/bootstrap.min.js"></script>
    <script src="/Users/mhughes/git/bnpy2/profile/assets/js/main.js"></script>

  </body>
</html>
