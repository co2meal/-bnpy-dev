<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Profiling Results</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Bootstrap -->
    <link href="../../assets/css/bootstrap.min.css" rel="stylesheet" media="screen">
    <link href="../../assets/css/docs.css" rel="stylesheet">
    <!-- <link href="//netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet"> -->
    <link rel="stylesheet" href="../../assets/css/font-awesome/font-awesome.min.css">
  </head>

  <body id="top">
    <header class="navbar navbar-inverse navbar-static-top bs-docs-nav" role="banner">
      <div class="container">
        <div class="navbar-header">
          <button class="navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a href="../index.html" class="navbar-brand">Profiling Results</a>
        </div>
        <nav class="collapse navbar-collapse bs-navbar-collapse" role="navigation">
          <ul class="nav navbar-nav">
            <li>
              <a href="../index.html">Summary</a>
            </li>
            <li class="active">
              <a href="#">calc_local_params</a>
            </li>
          </ul>
        </nav>
      </div>
    </header>
    <div class="container bs-docs-container">
      <div class="row">
	<div class="col-md-2">
	  <div class="bs-sidebar affix-top hidden-print" role="complementary">
	    <ul class="nav bs-sidenav">
              <li><a href="#function">calc_local_params</a></li>
	      <!-- <li><a href="#parents">Parents</a></li> -->
	      <!-- <li><a href="#children">Possible Children</a></li> -->
	      <li><a href="#listing">Function Listing</a></li>
	    </ul>

	  </div>
	</div>
        <div class="col-md-10">
	  <div class="page-header" id="function">
	    <h1>calc_local_params</h1>
	  </div>

          <p>1207776 Calls, 157.343 s</p>
	  <p>Generated 14:46:01 01/05/14 EST</p>
          <p>Function in file <a href="/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/HDPModel.py">/Users/mhughes/git/bnpy2/bnpy/allocmodel/admix/HDPModel.py</a></p>

          <h3 id="listing">Function listing</h3>
          <table class="table table-borderless table-condensed">
            <tr>
              <th>time</th>
              <th>calls</th>
              <th>line</th>
              <th>code</th>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line79">79</td>
              <td><pre class="prettyprint">   @profile</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line80">80</td>
              <td><pre class="prettyprint">   def calc_local_params( self, Data, LP, nCoordAscentIters=10):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line81">81</td>
              <td><pre class="prettyprint">       ''' Calculate document-specific quantities (E-step)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line82">82</td>
              <td><pre class="prettyprint">         Alternate updates to two terms until convergence</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line83">83</td>
              <td><pre class="prettyprint">           (1) Approx posterior on topic-token assignment</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line84">84</td>
              <td><pre class="prettyprint">                q(word_variational | word_token_variables)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line85">85</td>
              <td><pre class="prettyprint">           (2) Approx posterior on doc-topic probabilities</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line86">86</td>
              <td><pre class="prettyprint">                q(doc_variational | document_topic_variables)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line87">87</td>
              <td><pre class="prettyprint"></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line88">88</td>
              <td><pre class="prettyprint">         Returns</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line89">89</td>
              <td><pre class="prettyprint">         -------</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line90">90</td>
              <td><pre class="prettyprint">         LP : local params dict, with fields</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line91">91</td>
              <td><pre class="prettyprint">             Pi : nDoc x K+1 matrix, </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line92">92</td>
              <td><pre class="prettyprint">                row d has params for doc d's Dirichlet over K+1 topics</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line93">93</td>
              <td><pre class="prettyprint">             word_variational : nDistinctWords x K matrix</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line94">94</td>
              <td><pre class="prettyprint">                row i has params for word i's Discrete distr over K topics</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line95">95</td>
              <td><pre class="prettyprint">             DocTopicCount : nDoc x K matrix</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line96">96</td>
              <td><pre class="prettyprint">       '''</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line97">97</td>
              <td><pre class="prettyprint">       # When given no prev. local params LP, need to initialize from scratch</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line98">98</td>
              <td><pre class="prettyprint">       # this forces likelihood to drive the first round of local assignments</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>369</td>
              <td id="line99">99</td>
              <td><pre class="prettyprint">       if 'alphaPi' not in LP:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>31</td>
              <td id="line100">100</td>
              <td><pre class="prettyprint">           LP['alphaPi'] = np.ones((Data.nDoc,self.K+1))</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line101">101</td>
              <td><pre class="prettyprint">       else:</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>338</td>
              <td id="line102">102</td>
              <td><pre class="prettyprint">           assert LP['alphaPi'].shape[1] == self.K + 1</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line103">103</td>
              <td><pre class="prettyprint"></pre></td>
            </tr>
            
            <tr class="">
              <td>0.16 s</td>
              <td>369</td>
              <td id="line104">104</td>
              <td><pre class="prettyprint">       LP = self.calc_ElogPi(LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>369</td>
              <td id="line105">105</td>
              <td><pre class="prettyprint">       prevVec = LP['alphaPi'].flatten()</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line106">106</td>
              <td><pre class="prettyprint"></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line107">107</td>
              <td><pre class="prettyprint">       # Allocate lots of memory once</pre></td>
            </tr>
            
            <tr class="">
              <td>0.98 s</td>
              <td>369</td>
              <td id="line108">108</td>
              <td><pre class="prettyprint">       LP['word_variational'] = np.zeros(LP['E_logsoftev_WordsData'].shape)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line109">109</td>
              <td><pre class="prettyprint"></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line110">110</td>
              <td><pre class="prettyprint">       # Repeat until converged...</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>3996</td>
              <td id="line111">111</td>
              <td><pre class="prettyprint">       for ii in xrange(nCoordAscentIters):</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line112">112</td>
              <td><pre class="prettyprint">           # Update word_variational field of LP</pre></td>
            </tr>
            
            <tr class="danger">
              <td>1.3e+02 s</td>
              <td>3634</td>
              <td id="line113">113</td>
              <td><pre class="prettyprint">           LP = self.get_word_variational(Data, LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line114">114</td>
              <td><pre class="prettyprint">       </pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line115">115</td>
              <td><pre class="prettyprint">           # Update DocTopicCount field of LP</pre></td>
            </tr>
            
            <tr class="">
              <td>0.03 s</td>
              <td>3634</td>
              <td id="line116">116</td>
              <td><pre class="prettyprint">           LP['DocTopicCount'] = np.zeros((Data.nDoc,self.K))</pre></td>
            </tr>
            
            <tr class="">
              <td>1.8 s</td>
              <td>1207776</td>
              <td id="line117">117</td>
              <td><pre class="prettyprint">           for d in xrange(Data.nDoc):</pre></td>
            </tr>
            
            <tr class="">
              <td>6.2 s</td>
              <td>1204142</td>
              <td id="line118">118</td>
              <td><pre class="prettyprint">               start,stop = Data.doc_range[d,:]</pre></td>
            </tr>
            
            <tr class="">
              <td>1.8 s</td>
              <td>1204142</td>
              <td id="line119">119</td>
              <td><pre class="prettyprint">               LP['DocTopicCount'][d,:] = np.dot(</pre></td>
            </tr>
            
            <tr class="">
              <td>3.1 s</td>
              <td>1204142</td>
              <td id="line120">120</td>
              <td><pre class="prettyprint">                                          Data.word_count[start:stop],        </pre></td>
            </tr>
            
            <tr class="">
              <td>14 s</td>
              <td>1204142</td>
              <td id="line121">121</td>
              <td><pre class="prettyprint">                                          LP['word_variational'][start:stop,:]</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line122">122</td>
              <td><pre class="prettyprint">                                          )</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line123">123</td>
              <td><pre class="prettyprint">           # Update doc_variational field of LP</pre></td>
            </tr>
            
            <tr class="">
              <td>0.36 s</td>
              <td>3634</td>
              <td id="line124">124</td>
              <td><pre class="prettyprint">           LP = self.get_doc_variational(Data, LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>1.5 s</td>
              <td>3634</td>
              <td id="line125">125</td>
              <td><pre class="prettyprint">           LP = self.calc_ElogPi(LP)</pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line126">126</td>
              <td><pre class="prettyprint"></pre></td>
            </tr>
            
            <tr class="">
              <td>--</td>
              <td>0</td>
              <td id="line127">127</td>
              <td><pre class="prettyprint">           # Assess convergence </pre></td>
            </tr>
            
            <tr class="">
              <td>0.034 s</td>
              <td>3634</td>
              <td id="line128">128</td>
              <td><pre class="prettyprint">           curVec = LP['alphaPi'].flatten()</pre></td>
            </tr>
            
            <tr class="">
              <td>0.53 s</td>
              <td>3634</td>
              <td id="line129">129</td>
              <td><pre class="prettyprint">           if prevVec is not None and np.allclose(prevVec, curVec):</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>7</td>
              <td id="line130">130</td>
              <td><pre class="prettyprint">               break</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>3627</td>
              <td id="line131">131</td>
              <td><pre class="prettyprint">           prevVec = curVec</pre></td>
            </tr>
            
            <tr class="">
              <td>< 0.01 s</td>
              <td>369</td>
              <td id="line132">132</td>
              <td><pre class="prettyprint">       return LP</pre></td>
            </tr>
            
          </table>
        </div>
      </div>
    </div>

    <a href="#top" class="scrollToTop hidden-phone" >
      <i class="icon-chevron-up"></i>
    </a>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://code.jquery.com/jquery.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="../../assets/js/bootstrap.min.js"></script>
    <script src="../../assets/js/main.js"></script>
    <script src="https://google-code-prettify.googlecode.com/svn/loader/run_prettify.js"></script>
  </body>
</html>
