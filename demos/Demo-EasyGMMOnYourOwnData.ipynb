{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Easy Gaussian Mixture Model On Your Own Data\n",
      "\n",
      "## Goal\n",
      "\n",
      "This doc shows how to apply bnpy to your own dataset.  We'll specifically discuss fitting a Gaussian Mixture Model with EM, but the workflow here generalizes to any model and learning algorithm.\n",
      "\n",
      "Our focus here is on a workflow you can implement directly in Python scripts.  This closely follows the same flow used in most other demos which look at our **command line** tools instead.\n",
      "\n",
      "## Representing your Data\n",
      "**bnpy** supports several data formats depending what type of numbers you observe (real vectors, word counts, binary vectors, etc.).  See the [DataFormat doc](../Code/Data/DataFormat.md) for some key details.\n",
      "\n",
      "For this tutorial, we'll focus on modeling observed vectors of real numbers.  A Gaussian mixture model makes sense for this data type.\n",
      "\n",
      "All you need is to represent your data as a Numpy array, where each **row** is an observed vector. Here we'll just fill up a random matrix so you get the idea. Once a Numpy array is defined, we create an instance of **bnpy**'s built-in data type \"XData,\" which is just a thin-wrapper around the X array that enables **bnpy** to do its thing.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import bnpy\n",
      "\n",
      "#### Fill a matrix X with your data\n",
      "X = np.random.randn(100,2)\n",
      "\n",
      "#### Convert it into a bnpy data object\n",
      "Data = bnpy.data.XData(X)\n",
      "\n",
      "#### Apply any supported model + learning alg\n",
      "#### Using syntax exactly like calling Run from cmd line\n",
      "\n",
      "kwargs = dict(K=5, nLap=50, printEvery=10, initname='randexamples')\n",
      "hmodel, Info = bnpy.run(Data, 'MixModel', 'Gauss', 'EM', **kwargs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "X Data\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  size: 100 units (single observations)\n",
        "  dimension: 2\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Allocation Model:  Finite mixture with K=5. Dir prior param 1.00\n",
        "Obs. Data  Model:  Gaussian with full covariance.\n",
        "Obs. Data  Prior:  Gauss-Wishart on each mean/prec matrix pair: mu, Lam\n",
        "  E[ mu[k] ]     = [ 0.  0.]\n",
        "  E[ CovMat[k] ] = \n",
        "  [[ 1.  0.]\n",
        "   [ 0.  1.]]\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Learn Alg: EM\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Trial  1/1 | alg. seed: 4226944 | data order seed: 8541952\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "savepath: /Users/Jens/Dropbox/dev/research/ML/out/UnknownData/defaultjob/1\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        1/50 after      0 sec. | K    5 | ev -2.438814854e+07 |  \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        2/50 after      0 sec. | K    5 | ev -1.353561937e+00 | Ndiff      1.871 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       10/50 after      0 sec. | K    5 | ev -1.276409265e+00 | Ndiff      0.206 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       20/50 after      0 sec. | K    5 | ev -1.268387544e+00 | Ndiff      0.119 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       30/50 after      0 sec. | K    5 | ev -1.266342347e+00 | Ndiff      0.218 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       40/50 after      0 sec. | K    5 | ev -1.262759903e+00 | Ndiff      0.214 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "       50/50 after      0 sec. | K    5 | ev -1.259069823e+00 | Ndiff      0.183 \n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "... done. not converged. max laps thru data exceeded.\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "That's it. We can call **run** just like we do from the command line, providing exactly the same keyword options.\n",
      "\n",
      "The \"kwargs\" variable is a keyword arguments dictionary. You can specify all kinds of options, such as how many components (K) to fit, the number of laps through the data (nLap), how often to print parameters (printEvery), initialization procedures, and more.  These arguments have *exactly the same* names and behavior as the command line options when running Learn.py as a script.\n",
      "\n",
      "## Return Values\n",
      "\n",
      "**run** returns three objects:\n",
      "\n",
      "* hmodel : **bnpy** HModel, whose parameters were fit to the Data\n",
      "* LP : local parameters dict, containing learned hidden variables specific to the Data \n",
      "* Info : dictionary of properties about the run.\n",
      "  * evBound : scalar value of the log evidence of the data (ELBO) under the final model\n",
      "  * evTrace : vector of evBound from each recorded step of the run\n",
      "  \n",
      "### More about the model\n",
      "\n",
      "See [TODO](TODO).\n",
      "\n",
      "### More about local parameters\n",
      "\n",
      "For the Gaussian mixture model, the LP dictionary contains the posterior \"responsibilities\" for each data item.\n",
      "\n",
      "Within LP, there is a 'resp' field containing an N-by-K matrix. Each row gives the posterior responsibilities for data example n. Each row should sum to one.\n",
      "\n",
      "resp[n,k] = p(z_n = k | x_n )\n",
      "\n",
      "### More about an experiment's Info dict\n",
      "\n",
      "See [TODO](TODO)."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}